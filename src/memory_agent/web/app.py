import os
import math
import streamlit as st

from memory_agent.models.memory_index import MemoryIndexQwen
from memory_agent.config import UPLOAD_DIR


# ========== åŸºæœ¬è®¾ç½® ==========

st.set_page_config(
    page_title="Personal Long-Term Memory Agent (Qwen)",
    page_icon="ğŸ§ ",
    layout="wide",
)

if "memory_index" not in st.session_state:
    st.session_state.memory_index: MemoryIndexQwen | None = None

if "chat_messages" not in st.session_state:
    st.session_state.chat_messages = []

if "system_prompt" not in st.session_state:
    st.session_state.system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªä¸ªäººé•¿æœŸè®°å¿†åŠ©æ‰‹ï¼Œå¯ä»¥è®¿é—®ç”¨æˆ·çš„å¤šæ¨¡æ€è®°å¿†ï¼ˆæ–‡æœ¬ã€å›¾ç‰‡ã€è§†é¢‘ã€éŸ³é¢‘ã€è™šæ‹Ÿç¬”è®°ï¼‰ã€‚"
        "ç³»ç»Ÿå·²ç»ä¸ºä½ æ£€ç´¢å¥½äº†å’Œé—®é¢˜ç›¸å…³çš„è®°å¿†å¿«ç…§ï¼Œè¯·åŸºäºè¿™äº›ä¿¡æ¯è¿›è¡Œå›ç­”ã€‚"
        "å¦‚æœè®°å¿†ä¸è¶³ä»¥æ”¯æŒç¡®å®šç»“è®ºï¼Œè¯·æ˜ç¡®è¯´æ˜ä¸ç¡®å®šã€‚"
    )


# ========== å·¥å…·å‡½æ•° ==========

def ensure_index_loaded() -> bool:
    if st.session_state.memory_index is None:
        st.warning("âš ï¸ è¯·å…ˆåœ¨å·¦ä¾§åŠ è½½ç´¢å¼•æ–‡ä»¶ï¼ˆ.ptï¼‰")
        return False
    return True


def call_qwen_chat(messages, model_name: str):
    from openai import OpenAI
    client = OpenAI(
        api_key="sk-249bef7cbed5492294eb70ba9f3a3de1",
        # api_key=os.environ.get("DASHSCOPE_API_KEY"),
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )
    resp = client.chat.completions.create(
        model=model_name,
        messages=messages,
        temperature=0.3,
    )
    return resp.choices[0].message.content


def render_video_meta(parent):
    """
    åœ¨æ£€ç´¢ç»“æœä¸­å±•ç¤ºè§†é¢‘ç‰¹æœ‰çš„ä¿¡æ¯ï¼š
    - è§†é¢‘æ’­æ”¾å™¨
    - ä¸€å¥è¯æ‘˜è¦
    - æ—¶é—´çº¿ï¼ˆtimelineï¼‰
    - ç« èŠ‚åˆ—è¡¨
    - å…³é”®å¸§ç”»å»Šï¼ˆå« caption / OCR / objectsï¼‰
    """
    meta = parent.meta or {}

    # 1. è§†é¢‘æ’­æ”¾å™¨
    if os.path.exists(parent.path):
        st.video(parent.path)

    # 2. ä¸€å¥è¯æ€»ç»“
    if "summary" in meta:
        st.markdown(f"**è§†é¢‘æ‘˜è¦ï¼š** {meta['summary']}")

    # 3. æ—¶é—´çº¿ & æ—¶é—´çº¿æ‘˜è¦
    if "timeline_summary" in meta:
        with st.expander("ğŸ•’ æ—¶é—´çº¿æ€»ç»“ï¼ˆTimeline Summaryï¼‰"):
            st.write(meta["timeline_summary"])

    if "timeline" in meta and meta["timeline"]:
        with st.expander("ğŸ§¬ å…³é”®å¸§æ—¶é—´çº¿ï¼ˆTimelineï¼‰"):
            st.text(meta["timeline"])

    # 4. ç« èŠ‚åˆ—è¡¨
    chapters = meta.get("chapters", [])
    if chapters:
        with st.expander("ğŸ“š è§†é¢‘ç« èŠ‚ï¼ˆChaptersï¼‰"):
            for i, ch in enumerate(chapters, 1):
                start = ch.get("start", 0.0)
                end = ch.get("end", 0.0)
                mm_s = f"{int(start // 60):02d}:{int(start % 60):02d}"
                mm_e = f"{int(end // 60):02d}:{int(end % 60):02d}"
                st.markdown(f"**ç¬¬{i}ç« **  ({mm_s} ~ {mm_e})")
                st.markdown(ch.get("raw", "ï¼ˆæ— ç« èŠ‚å†…å®¹ï¼‰"))
                st.markdown("---")

    # 5. å…³é”®å¸§ç”»å»Š
    keyframes = meta.get("keyframes", [])
    if keyframes:
        with st.expander("ğŸ–¼ å…³é”®å¸§ç”»å»Šï¼ˆKeyframes Galleryï¼‰"):
            cols_per_row = 3
            rows = math.ceil(len(keyframes) / cols_per_row)
            for r in range(rows):
                cols = st.columns(cols_per_row)
                for c in range(cols_per_row):
                    idx = r * cols_per_row + c
                    if idx >= len(keyframes):
                        break
                    kf = keyframes[idx]
                    with cols[c]:
                        ts = kf.get("timestamp", 0.0)
                        mm = int(ts // 60)
                        ss = int(ts % 60)
                        t = f"{mm:02d}:{ss:02d}"

                        fp = kf.get("frame_path", "")
                        if os.path.exists(fp):
                            st.image(fp, caption=f"t={t}")

                        st.caption(kf.get("caption", ""))
                        if kf.get("ocr_text"):
                            with st.expander("OCR æ–‡æœ¬"):
                                st.text(kf["ocr_text"])
                        if kf.get("objects"):
                            st.caption("æ£€æµ‹åˆ°ç‰©ä½“: " + ", ".join(kf["objects"]))


def render_grouped_results(groups: list[dict]):
    if not groups:
        st.info("æ²¡æœ‰æ£€ç´¢ç»“æœã€‚")
        return

    for rank, g in enumerate(groups, start=1):
        parent = g["parent"]
        children = g["children"]
        score = g["parent_score"]

        with st.container(border=True):
            st.markdown(f"### #{rank} | æ¨¡æ€ï¼š{parent.modality} | ç›¸ä¼¼åº¦ï¼š{score:.3f}")
            st.text(f"è·¯å¾„: {parent.path}")
            st.text(f"æ—¶é—´: {parent.timestamp}")
            st.markdown(f"**æ‘˜è¦ï¼š** {parent.preview_text}")

            if "summary" in parent.meta:
                with st.expander("å±•å¼€å®Œæ•´æ‘˜è¦"):
                    st.write(parent.meta["summary"])

            # åª’ä½“å±•ç¤ºï¼ˆåŸç‰ˆæœ¬ï¼‰
            if parent.modality == "image" and os.path.exists(parent.path):
                st.image(parent.path)
            elif parent.modality == "video":
                render_video_meta(parent)
            elif parent.modality == "audio" and os.path.exists(parent.path):
                st.audio(parent.path)

            # å­èŠ‚ç‚¹
            if children:
                st.markdown("**ç›¸å…³å­ç‰‡æ®µï¼š**")
                for child, sc in children:
                    st.markdown(f"- {child.modality} | ç›¸ä¼¼åº¦ {sc:.3f}")
                    st.markdown(f"  å†…å®¹ï¼š{child.preview_text}")
                    if "keyframe_path" in child.meta:
                        kf = child.meta["keyframe_path"]
                        if os.path.exists(kf):
                            st.image(kf, caption="å…³é”®å¸§", use_container_width=True)

        st.markdown("---")


# ========== Sidebar ==========

st.sidebar.header("âš™ æ§åˆ¶å°")

index_path = st.sidebar.text_input("ç´¢å¼•æ–‡ä»¶è·¯å¾„ (.pt)", value="memory_index.pt")

if st.sidebar.button("åŠ è½½ç´¢å¼•"):
    if not os.path.exists(index_path):
        st.sidebar.error(f"ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼š{index_path}")
    else:
        with st.spinner("æ­£åœ¨åŠ è½½ç´¢å¼•..."):
            idx = MemoryIndexQwen.load(index_path)
        st.session_state.memory_index = idx
        st.sidebar.success("ç´¢å¼•åŠ è½½å®Œæˆï¼")

if st.session_state.memory_index is not None:
    st.sidebar.markdown(f"**è®°å¿†æ¡ç›®æ•°ï¼š** {len(st.session_state.memory_index.items)}")

st.sidebar.markdown("---")

llm_model = st.sidebar.text_input(
    "Qwen å¯¹è¯æ¨¡å‹å",
    value="qwen-flash",  # è¿™é‡Œå»ºè®®ä½ æ¢æˆè‡ªå·±å®é™…å¯ç”¨çš„æ¨¡å‹å
)

top_k = st.sidebar.slider("æ£€ç´¢ top-k çˆ¶èŠ‚ç‚¹", 3, 20, 8)
max_children = st.sidebar.slider("æ¯ä¸ªçˆ¶èŠ‚ç‚¹å±•ç¤ºå­èŠ‚ç‚¹æ•°é‡", 1, 10, 3)

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“¤ ä¸Šä¼ æ–°æ–‡ä»¶ï¼ˆå¢é‡æ›´æ–°ç´¢å¼•ï¼‰")

uploaded = st.sidebar.file_uploader(
    "é€‰æ‹©æ–‡ä»¶ï¼ˆæ–‡æœ¬/å›¾ç‰‡/éŸ³é¢‘/è§†é¢‘ï¼‰",
    type=["txt", "md", "jpg", "jpeg", "png", "mp4", "mov", "avi", "mp3", "wav", "m4a"],
)

if uploaded is not None:
    os.makedirs(UPLOAD_DIR, exist_ok=True)
    save_path = os.path.join(UPLOAD_DIR, uploaded.name)
    with open(save_path, "wb") as f:
        f.write(uploaded.read())

    st.sidebar.success(f"å·²ä¿å­˜åˆ° {save_path}")

    if st.sidebar.button("åŠ å…¥è®°å¿†åº“"):
        if not ensure_index_loaded():
            st.stop()
        with st.spinner("æ­£åœ¨å¤„ç†å¹¶æ›´æ–°ç´¢å¼•..."):
            st.session_state.memory_index.add_file(save_path)
            st.session_state.memory_index.save(index_path)
        st.sidebar.success("å·²åŠ å…¥ç´¢å¼•ï¼")


# ========== Tabs ==========

tab_search, tab_chat = st.tabs(["ğŸ” æ£€ç´¢æ¨¡å¼", "ğŸ’¬ èŠå¤©æ¨¡å¼"])


# ---------- Tab 1: Search ----------
with tab_search:
    st.header("ğŸ” æ£€ç´¢ä½ çš„å¤šæ¨¡æ€è®°å¿†åº“ï¼ˆQwenï¼‰")

    query = st.text_input("è¾“å…¥æŸ¥è¯¢å†…å®¹ï¼š", key="search_query")

    if st.button("æ‰§è¡Œæ£€ç´¢"):
        if not ensure_index_loaded():
            st.stop()
        with st.spinner("æ£€ç´¢ä¸­..."):
            groups = st.session_state.memory_index.search_grouped(
                query, top_k=top_k, max_children=max_children
            )
        render_grouped_results(groups)


# ---------- Tab 2: Chat ----------
with tab_chat:
    st.header("ğŸ’¬ å¸¦è®°å¿†æ£€ç´¢çš„èŠå¤©")

    # å±•ç¤ºå†å²æ¶ˆæ¯
    for m in st.session_state.chat_messages:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    user_input = st.chat_input("è¯´ç‚¹ä»€ä¹ˆ...")

    if user_input:
        if not ensure_index_loaded():
            st.stop()

        # 1. å…ˆæŠŠç”¨æˆ·è¾“å…¥åŠ å…¥èŠå¤©è®°å½•å¹¶å±•ç¤º
        st.session_state.chat_messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # 2. æ£€ç´¢ç›¸å…³è®°å¿†
        idx = st.session_state.memory_index
        with st.spinner("æ£€ç´¢ç›¸å…³è®°å¿†..."):
            grouped = idx.search_grouped(user_input, top_k=top_k, max_children=max_children)
            mem_ctx = idx.build_grouped_llm_context(user_input, grouped)

        # 3. è°ƒç”¨ Qwen Chat
        messages_for_llm = [
            {"role": "system", "content": st.session_state.system_prompt},
        ]
        # æŠŠå†å²å¯¹è¯å¡è¿›å»
        for m in st.session_state.chat_messages:
            if m["role"] in ("user", "assistant"):
                messages_for_llm.append(m)

        # å†é™„åŠ ä¸€æ¡å¸¦â€œè®°å¿†å¿«ç…§â€çš„ user æ¶ˆæ¯
        messages_for_llm.append({
            "role": "user",
            "content": (
                "ä¸‹é¢æ˜¯æ£€ç´¢åˆ°çš„ç›¸å…³è®°å¿†å¿«ç…§ï¼Œè¯·ç»“åˆè¿™äº›å†…å®¹å›ç­”ä¸Šé¢çš„é—®é¢˜ï¼š\n\n"
                + mem_ctx
            )
        })

        with st.chat_message("assistant"):
            with st.spinner("Qwen æ­£åœ¨æ€è€ƒ..."):
                answer = call_qwen_chat(messages_for_llm, model_name=llm_model)
                st.markdown(answer)

        st.session_state.chat_messages.append(
            {"role": "assistant", "content": answer}
        )
